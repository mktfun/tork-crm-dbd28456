

# Plano: Progressive Scan - Escaneamento Progressivo por Fatias de PÃ¡ginas

## Status da Arquitetura Atual

### O que jÃ¡ estÃ¡ implementado (v2.1)
O sistema atual jÃ¡ possui uma arquitetura sÃ³lida com zero dependÃªncia de IA:

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EDGE FUNCTION: analyze-policy                      â”‚
â”‚                                                                 â”‚
â”‚  1. Recebe PDF base64                                          â”‚
â”‚  2. Trim para 2 pÃ¡ginas (mÃ¡x 512KB)                            â”‚
â”‚  3. ExtraÃ§Ã£o LOCAL (regex em PDF streams)                      â”‚
â”‚  4. Se qualidade < 30% â†’ OCR.space Engine 2                    â”‚
â”‚  5. Retorna { rawText, source, stats }                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FRONTEND: universalPolicyParser (v2.1)             â”‚
â”‚                                                                 â”‚
â”‚  - Anchor Search com raio de 150 caracteres                    â”‚
â”‚  - InferÃªncia de Ramo via keywords                             â”‚
â”‚  - NormalizaÃ§Ã£o de Seguradora via aliases                      â”‚
â”‚  - CÃ¡lculo de confianÃ§a baseado em campos                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SERVICE: upsertClientByDocument                    â”‚
â”‚                                                                 â”‚
â”‚  - Valida CPF (11) ou CNPJ (14)                                â”‚
â”‚  - Busca existente â†’ retorna ID                                â”‚
â”‚  - NÃ£o existe â†’ cria com dados extraÃ­dos                       â”‚
â”‚  - Tratamento de conflito unique constraint                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Banco de Dados: Ãndices jÃ¡ existentes
```sql
-- ÃšNICO para upsert (jÃ¡ criado)
idx_clientes_cpf_cnpj_user_unique  (user_id, cpf_cnpj) WHERE cpf_cnpj IS NOT NULL
idx_clientes_doc_user              (user_id, cpf_cnpj) WHERE cpf_cnpj IS NOT NULL
```

## Problema Identificado

O limite de **2 pÃ¡ginas** na funÃ§Ã£o atual pode perder dados importantes em PDFs onde:
- Dados de veÃ­culo estÃ£o na pÃ¡gina 3 (comum na Tokio Marine)
- PrÃªmio lÃ­quido aparece na pÃ¡gina 4 (comum em propostas)
- CPF do segurado estÃ¡ na pÃ¡gina 2 mas vigÃªncia na pÃ¡gina 3

### SoluÃ§Ã£o: Progressive Scan

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                FRONTEND: Progressive Scan Loop                  â”‚
â”‚                                                                 â”‚
â”‚  accumulatedText = ''                                          â”‚
â”‚  for page = 1 to MAX_PAGES step 2:                             â”‚
â”‚    1. Chama Edge Function (startPage, endPage)                 â”‚
â”‚    2. accumulatedText += rawText                               â”‚
â”‚    3. parsedData = universalPolicyParser(accumulatedText)      â”‚
â”‚    4. SE confidenceScore >= 80 â†’ PARA                          â”‚
â”‚    5. SENÃƒO â†’ continua prÃ³ximas pÃ¡ginas                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Arquivos a Modificar

| Arquivo | MudanÃ§as |
|---------|----------|
| `supabase/functions/analyze-policy/index.ts` | Adicionar parÃ¢metros `startPage` e `endPage` para extraÃ§Ã£o seletiva |
| `src/utils/universalPolicyParser.ts` | Adicionar Sliding Window v3.0 com correÃ§Ã£o de ruÃ­do OCR |
| `src/components/policies/ImportPoliciesModal.tsx` | Implementar loop progressivo com threshold de confianÃ§a |

---

## SeÃ§Ã£o TÃ©cnica

### 1. Edge Function: ParÃ¢metros de PaginaÃ§Ã£o

Modificar `analyze-policy` para aceitar `startPage` e `endPage`:

```typescript
// Novos parÃ¢metros opcionais
const startPage = body.startPage || 1;
const endPage = body.endPage || 2;

// Nova funÃ§Ã£o de trim com range
async function extractPageRange(base64: string, startPage: number, endPage: number): Promise<string> {
  const pdfBytes = Uint8Array.from(atob(base64), c => c.charCodeAt(0));
  const pdfDoc = await PDFDocument.load(pdfBytes);
  const pageCount = pdfDoc.getPageCount();
  
  // Ajusta range para nÃ£o exceder total
  const actualEnd = Math.min(endPage, pageCount);
  const actualStart = Math.max(1, startPage);
  
  if (actualStart > pageCount) {
    return ''; // PÃ¡ginas solicitadas nÃ£o existem
  }
  
  // Cria novo PDF apenas com as pÃ¡ginas solicitadas
  const newDoc = await PDFDocument.create();
  for (let i = actualStart - 1; i < actualEnd; i++) {
    const [page] = await newDoc.copyPages(pdfDoc, [i]);
    newDoc.addPage(page);
  }
  
  const newBytes = await newDoc.save();
  return uint8ArrayToBase64(new Uint8Array(newBytes));
}
```

A resposta incluirÃ¡ metadados:
```typescript
return {
  success: true,
  rawText: rawText,
  source: source,
  pageRange: { start: startPage, end: actualEnd, total: pageCount },
  hasMorePages: actualEnd < pageCount,
};
```

### 2. Parser v3.0: Sliding Window + CorreÃ§Ã£o de RuÃ­do

Melhorias no `universalPolicyParser.ts`:

```typescript
// NOVA funÃ§Ã£o de normalizaÃ§Ã£o v3.0
export function normalizeOcrText(rawText: string): string {
  let text = rawText
    .replace(/\r\n/g, '\n')
    .replace(/\t+/g, ' ')
    .toUpperCase();
  
  // NOVO: Remove espaÃ§os entre dÃ­gitos (OCR noise)
  // "1 2 3 . 4 5 6 . 7 8 9 - 0 0" â†’ "123.456.789-00"
  text = text.replace(/(\d)\s+(?=\d)/g, '$1');
  
  // NOVO: Corrige Oâ†’0 e lâ†’1 em contexto numÃ©rico (OCR noise)
  // "CPF: 123.456.789-O0" â†’ "CPF: 123.456.789-00"
  text = text.replace(/(\d)[O](\d)/g, '$10$2');
  text = text.replace(/(\d)[O]$/g, '$10');    // Final O
  text = text.replace(/^[O](\d)/g, '0$1');    // Inicial O
  text = text.replace(/(\d)[lI](\d)/gi, '$11$2');
  
  // Remove mÃºltiplos espaÃ§os
  text = text.replace(/[ ]{2,}/g, ' ');
  text = text.replace(/\n{3,}/g, '\n\n');
  
  return text.trim();
}

// NOVA funÃ§Ã£o de extraÃ§Ã£o por janela deslizante
function extractByAnchor(
  text: string,
  anchors: string[],
  regex: RegExp,
  windowSize: number = 100
): string | null {
  const results: { value: string; confidence: number }[] = [];
  
  for (const anchor of anchors) {
    let searchIdx = 0;
    while (true) {
      const anchorIdx = text.indexOf(anchor.toUpperCase(), searchIdx);
      if (anchorIdx === -1) break;
      
      const windowStart = anchorIdx + anchor.length;
      const window = text.substring(windowStart, windowStart + windowSize);
      
      const match = window.match(regex);
      if (match?.[1]) {
        const value = match[1].trim();
        const confidence = 100 - (match.index || 0);
        results.push({ value, confidence });
      }
      
      searchIdx = anchorIdx + 1;
    }
  }
  
  if (results.length === 0) return null;
  results.sort((a, b) => b.confidence - a.confidence);
  return results[0].value;
}
```

Sistema de pesos para confianÃ§a:
```typescript
// Pesos para cÃ¡lculo de confianÃ§a
const CONFIDENCE_WEIGHTS = {
  cpf_cnpj: 50,    // CrÃ­tico: identificaÃ§Ã£o do cliente
  numero_apolice: 20,
  placa: 20,
  datas: 10,       // data_inicio + data_fim
  premio: 10,
  nome: 10,
  seguradora: 10,
  ramo: 5,
};

// Score mÃ­nimo para parar o progressive scan
const CONFIDENCE_THRESHOLD = 80;
```

### 3. Frontend: Loop Progressivo

Modificar `processFilesIndividually` em `ImportPoliciesModal.tsx`:

```typescript
const processFileProgressively = async (file: File): Promise<ParsedPolicy> => {
  let accumulatedText = '';
  let currentPage = 1;
  const MAX_PAGES = 6; // Limite de seguranÃ§a
  let parsedData: ParsedPolicy | null = null;
  let lastPageRange = { total: 0, hasMore: true };
  
  const base64 = await fileToBase64(file);
  
  while (currentPage <= MAX_PAGES && lastPageRange.hasMore) {
    console.log(`ğŸ“„ [PROGRESSIVE] ${file.name}: pÃ¡ginas ${currentPage}-${currentPage + 1}`);
    
    // 1. Chama Edge Function para fatia de pÃ¡ginas
    const { data, error } = await supabase.functions.invoke('analyze-policy', {
      body: { 
        base64, 
        fileName: file.name, 
        mimeType: file.type,
        startPage: currentPage,
        endPage: currentPage + 1
      }
    });
    
    if (error || !data?.success) {
      console.warn(`âš ï¸ [PROGRESSIVE] Erro nas pÃ¡ginas ${currentPage}-${currentPage + 1}`);
      break;
    }
    
    // 2. Acumula texto
    accumulatedText += ' ' + data.rawText;
    lastPageRange = {
      total: data.pageRange?.total || 0,
      hasMore: data.hasMorePages || false
    };
    
    // 3. Parser no texto acumulado
    parsedData = parsePolicy(accumulatedText, file.name);
    
    console.log(`ğŸ” [PROGRESSIVE] ConfianÃ§a: ${parsedData.confidence}%, Campos: ${parsedData.matched_fields.length}`);
    
    // 4. Se confianÃ§a >= 80, para
    if (parsedData.confidence >= 80) {
      console.log(`âœ… [PROGRESSIVE] Threshold atingido! Parando na pÃ¡gina ${currentPage + 1}`);
      break;
    }
    
    // 5. PrÃ³ximas pÃ¡ginas
    currentPage += 2;
  }
  
  return parsedData || parsePolicy(accumulatedText, file.name);
};
```

---

## Fluxo Completo: Diagrama

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PROGRESSIVE SCAN FLOW                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  1. UPLOAD: PDF da Tokio Marine (8 pÃ¡ginas)                         â”‚
â”‚                                                                      â”‚
â”‚  2. LOOP PROGRESSIVO:                                                â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚     â”‚ IteraÃ§Ã£o 1: PÃ¡ginas 1-2                                     â”‚  â”‚
â”‚     â”‚ â†’ rawText: 15k chars                                        â”‚  â”‚
â”‚     â”‚ â†’ Parser: confianÃ§a 35% (sÃ³ seguradora encontrada)          â”‚  â”‚
â”‚     â”‚ â†’ CONTINUA                                                  â”‚  â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚     â”‚ IteraÃ§Ã£o 2: PÃ¡ginas 3-4                                     â”‚  â”‚
â”‚     â”‚ â†’ rawText acumulado: 30k chars                              â”‚  â”‚
â”‚     â”‚ â†’ Parser: confianÃ§a 85% (CPF+Placa+PrÃªmio+Datas)            â”‚  â”‚
â”‚     â”‚ â†’ PARA! Threshold atingido                                  â”‚  â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                      â”‚
â”‚  3. UPSERT: Cliente criado/vinculado via CPF                        â”‚
â”‚                                                                      â”‚
â”‚  4. TABELA: Campos preenchidos automaticamente                      â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Resultado Esperado

### Console Logs
```
ğŸ“„ [1/1] Processando: APOLICE TOKIO MARINE.pdf
ğŸ“„ [PROGRESSIVE] pÃ¡ginas 1-2
ğŸ“ [OCR] 15k caracteres (via LOCAL)
ğŸ” [PROGRESSIVE] ConfianÃ§a: 35%, Campos: 2
ğŸ“„ [PROGRESSIVE] pÃ¡ginas 3-4
ğŸ“ [OCR] 18k caracteres (via OCR)
ğŸ” [PROGRESSIVE] ConfianÃ§a: 85%, Campos: 8
âœ… [PROGRESSIVE] Threshold atingido! Parando na pÃ¡gina 4
ğŸ” [PARSER] CPF: 12345678900, ApÃ³lice: 987654321, Ramo: AUTOMÃ“VEL
âœ… [UPSERT] Cliente criado: abc-123-def
```

### Tabela de ConferÃªncia
- CPF preenchido e limpo (sem pontos/espaÃ§os)
- Placa detectada automaticamente
- Ramo = AUTOMÃ“VEL (inferido por keywords)
- Cliente vinculado ou criado

---

## ValidaÃ§Ã£o e Testes

| Passo | AÃ§Ã£o | Resultado |
|-------|------|-----------|
| 1 | Upload PDF Tokio Marine (dados na pÃ¡g 3) | Loop dispara 2 iteraÃ§Ãµes |
| 2 | Verificar console | Log mostra confianÃ§a crescente |
| 3 | Verificar tabela | CPF limpo, placa formatada |
| 4 | Salvar apÃ³lice | Cliente criado/vinculado |
| 5 | Upload mesmo PDF | Cliente NÃƒO duplicado |

---

## Complexidade e Estimativas

| Tarefa | Complexidade | Linhas |
|--------|--------------|--------|
| Edge Function: `extractPageRange()` | MÃ©dia | ~50 |
| Parser v3.0: `normalizeOcrText()` | Baixa | ~30 |
| Parser v3.0: `extractByAnchor()` | MÃ©dia | ~40 |
| Frontend: `processFileProgressively()` | MÃ©dia | ~60 |

**Total**: ~180 linhas de cÃ³digo

---

## Vantagens da Abordagem

1. **Economia de OCR**: Para PDFs onde dados estÃ£o nas primeiras 2 pÃ¡ginas, nÃ£o processa mais
2. **Cobertura completa**: Para PDFs complexos, processa atÃ© encontrar dados essenciais
3. **Limite de seguranÃ§a**: MÃ¡ximo 6 pÃ¡ginas evita estouro de memÃ³ria
4. **DeterminÃ­stico**: Mesmo PDF sempre produz mesmo resultado
5. **Zero IA**: Nenhum token de modelo de linguagem consumido

