

# Plano: Migra√ß√£o para Processamento Individual de Arquivos

## Diagn√≥stico do Sistema Atual

### Arquitetura Atual (Batch Processing)
```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     FRONTEND                                     ‚îÇ
‚îÇ  ImportPoliciesModal.tsx                                        ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  processBulkOCR():                                              ‚îÇ
‚îÇ    1. Converte TODOS os arquivos para Base64                   ‚îÇ
‚îÇ    2. Envia array √∫nico para ocr-bulk-analyze                  ‚îÇ
‚îÇ    3. Aguarda resposta √∫nica com TODAS as ap√≥lices             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ 1 requisi√ß√£o com N arquivos
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              EDGE FUNCTION: ocr-bulk-analyze                    ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  1. Recebe array de arquivos (files[])                         ‚îÇ
‚îÇ  2. Loop: PDF trimming + OCR.space (Engine 2 + isTable)        ‚îÇ
‚îÇ  3. Envia texto agregado para IA (Lovable Gateway)             ‚îÇ
‚îÇ  4. Retorna array de ap√≥lices extra√≠das                        ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  üî¥ PROBLEMA: Se 1 arquivo falhar ou usar muita RAM,           ‚îÇ
‚îÇ     toda a requisi√ß√£o falha (WORKER_LIMIT)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Problema Identificado
- A edge function `ocr-bulk-analyze` processa todos os arquivos em uma √∫nica execu√ß√£o
- Um PDF grande ou corrompido pode causar falha total
- Uso de mem√≥ria acumulativo: 4 PDFs √ó 5MB = 20MB+ na mesma inst√¢ncia

---

## Arquitetura Proposta (Individual Processing)

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     FRONTEND (Orquestrador)                     ‚îÇ
‚îÇ  ImportPoliciesModal.tsx                                        ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  processFilesIndividually():                                    ‚îÇ
‚îÇ    for (file of selectedFiles) {                               ‚îÇ
‚îÇ      try {                                                      ‚îÇ
‚îÇ        const result = await supabase.functions.invoke(...)     ‚îÇ
‚îÇ        results.push(result)     // ‚úÖ Sucesso isolado          ‚îÇ
‚îÇ      } catch (err) {                                           ‚îÇ
‚îÇ        errors.push(file.name)   // ‚ùå Falha isolada            ‚îÇ
‚îÇ      }                                                          ‚îÇ
‚îÇ    }                                                            ‚îÇ
‚îÇ    // Continua com os que deram certo                          ‚îÇ
‚îÇ    await reconcileAll(results)                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ N requisi√ß√µes (1 por arquivo)
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              EDGE FUNCTION: analyze-policy-single               ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  1. Recebe UM arquivo (base64, fileName, mimeType)             ‚îÇ
‚îÇ  2. PDF trimming (p√°ginas 1-2 apenas)                          ‚îÇ
‚îÇ  3. OCR.space com Engine 2 + isTable                           ‚îÇ
‚îÇ  4. IA via Lovable Gateway (mesmo prompt da bulk)              ‚îÇ
‚îÇ  5. Retorna dados de 1 ap√≥lice                                 ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚úÖ Isolamento total: falha de 1 n√£o afeta outros              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Mudan√ßas Detalhadas

### 1. Nova Edge Function: `analyze-policy-single`
**Arquivo**: `supabase/functions/analyze-policy-single/index.ts`

Por que criar nova fun√ß√£o em vez de modificar `analyze-policy`:
- A fun√ß√£o `analyze-policy` existente usa **Gemini direto** com schema diferente
- A `ocr-bulk-analyze` tem pipeline mais robusto (OCR.space + Lovable Gateway)
- Melhor isolar a nova l√≥gica para n√£o quebrar funcionalidades existentes

**Estrutura**:
```typescript
serve(async (req) => {
  const { base64, fileName, mimeType } = await req.json();
  
  // 1. PDF Trimming (p√°ginas 1-2) - c√≥digo reutilizado de ocr-bulk-analyze
  const miniPdfBytes = await trimPdf(base64);
  
  // 2. OCR.space (Engine 2, isTable=true)
  const extractedText = await callOcrSpace(miniPdfBytes);
  
  // 3. IA via Lovable Gateway (mesmo prompt robusto)
  const policy = await extractWithAI(extractedText, fileName);
  
  // 4. Retorna dados da ap√≥lice √∫nica
  return Response.json({
    success: true,
    data: policy,
    fileName: fileName
  });
});
```

### 2. Refatora√ß√£o do Frontend
**Arquivo**: `src/components/policies/ImportPoliciesModal.tsx`

**Substituir `processBulkOCR` por `processFilesIndividually`**:

```typescript
const processFilesIndividually = async () => {
  if (!user || files.length === 0) return;
  
  setStep('processing');
  const results: BulkOCRExtractedPolicy[] = [];
  const errors: { fileName: string; error: string }[] = [];
  
  // Processa cada arquivo individualmente
  for (let idx = 0; idx < files.length; idx++) {
    const file = files[idx];
    setProcessingStatus(prev => new Map(prev).set(idx, 'processing'));
    setOcrProgress(idx);
    
    try {
      const base64 = await fileToBase64(file);
      
      // üî• Chamada individual para cada arquivo
      const { data, error } = await supabase.functions.invoke('analyze-policy-single', {
        body: { 
          base64, 
          fileName: file.name, 
          mimeType: file.type 
        }
      });
      
      if (error) throw new Error(error.message);
      if (!data?.success) throw new Error(data?.error || 'Extra√ß√£o falhou');
      
      results.push(data.data);
      setProcessingStatus(prev => new Map(prev).set(idx, 'success'));
      
    } catch (err: any) {
      console.error(`‚ùå Falha em ${file.name}:`, err.message);
      errors.push({ fileName: file.name, error: err.message });
      setProcessingStatus(prev => new Map(prev).set(idx, 'error'));
      // ‚úÖ Continua com os pr√≥ximos arquivos (n√£o quebra o loop)
    }
  }
  
  setOcrProgress(files.length);
  
  if (results.length === 0) {
    toast.error('Nenhum arquivo processado com sucesso');
    setStep('upload');
    return;
  }
  
  // Mostra toast com estat√≠sticas
  if (errors.length > 0) {
    toast.warning(`${results.length} processados, ${errors.length} com erro`);
  }
  
  // Continua com reconcilia√ß√£o dos que deram certo
  await reconcileResults(results);
};
```

### 3. Ajustes na Edge Function Existente
**Arquivo**: `supabase/functions/analyze-policy/index.ts`

Esta fun√ß√£o **permanece inalterada** pois √© usada para outros fluxos (carteirinhas, etc).

### 4. Atualizar Config.toml
**Arquivo**: `supabase/config.toml`

```toml
[functions.analyze-policy-single]
verify_jwt = false
```

---

## Reutiliza√ß√£o de C√≥digo

Para evitar duplica√ß√£o, a nova fun√ß√£o `analyze-policy-single` ir√°:

1. **Reutilizar** a l√≥gica de PDF trimming do `ocr-bulk-analyze`
2. **Reutilizar** o prompt do sistema j√° otimizado
3. **Simplificar** a resposta para retornar apenas 1 ap√≥lice

**C√≥digo compartilhado a ser extra√≠do**:
- `uint8ArrayToBase64()` - convers√£o segura
- `trimPdf()` - corte de p√°ginas 1-2
- `callOcrSpace()` - chamada OCR Engine 2
- `extractPolicyWithAI()` - chamada Lovable Gateway
- `generateSmartTitle()` - gera√ß√£o de t√≠tulo

---

## Fluxo de Processamento Comparativo

| Aspecto | Batch (Atual) | Individual (Novo) |
|---------|---------------|-------------------|
| Requisi√ß√µes | 1 (N arquivos) | N (1 por arquivo) |
| Isolamento de falhas | ‚ùå Total failure | ‚úÖ Parcial |
| Uso de RAM | ‚ùå Acumulativo | ‚úÖ Reset por req |
| Feedback visual | ‚ö†Ô∏è Tudo ou nada | ‚úÖ Por arquivo |
| Network tab | 1 requisi√ß√£o | N requisi√ß√µes |
| Rate limit | ‚ö†Ô∏è 1 hit IA | ‚ö†Ô∏è N hits IA |

---

## Valida√ß√£o e Testes

1. **Teste de Isolamento**:
   - Subir 4 arquivos: 3 v√°lidos + 1 corrompido
   - Esperado: 3 processados com sucesso, 1 erro isolado

2. **Teste de Network**:
   - Abrir DevTools > Network
   - Subir 3 arquivos
   - Esperado: 3 requisi√ß√µes separadas para `analyze-policy-single`

3. **Teste de Mem√≥ria**:
   - Subir 5 PDFs de 4MB cada
   - Esperado: Sem erro WORKER_LIMIT (cada req < 50MB)

---

## Arquivos a Criar/Modificar

| Arquivo | A√ß√£o | Descri√ß√£o |
|---------|------|-----------|
| `supabase/functions/analyze-policy-single/index.ts` | **Criar** | Nova edge function para processamento individual |
| `supabase/config.toml` | **Modificar** | Adicionar config da nova fun√ß√£o |
| `src/components/policies/ImportPoliciesModal.tsx` | **Modificar** | Substituir `processBulkOCR` por `processFilesIndividually` |

**Arquivos mantidos inalterados**:
- `supabase/functions/ocr-bulk-analyze/index.ts` - mantido para compatibilidade
- `supabase/functions/analyze-policy/index.ts` - usado para carteirinhas
- `src/services/policyImportService.ts` - j√° tem upsert implementado

---

## Considera√ß√µes de Performance

### Lat√™ncia
- **Batch**: 1 requisi√ß√£o de ~10s (todos os arquivos)
- **Individual**: N requisi√ß√µes de ~3-5s cada (paralelo poss√≠vel no futuro)

### Rate Limiting
- **Lovable AI Gateway**: Verificar limites de requests/min
- **OCR.space**: 500 requests/dia no plano free

### Otimiza√ß√£o Futura
Para reduzir lat√™ncia total, podemos implementar **processamento paralelo controlado**:
```typescript
// Vers√£o otimizada (fase 2)
const concurrency = 2; // 2 arquivos por vez
const results = await processInBatches(files, concurrency, processFile);
```

---

## Estimativa de Complexidade

| Tarefa | Complexidade | Linhas de C√≥digo |
|--------|--------------|------------------|
| Nova edge function | Alta | ~200 linhas |
| Refatorar frontend | M√©dia | ~80 linhas modificadas |
| Config.toml | Baixa | 3 linhas |
| Testes | Baixa | Manual |

**Total: 1 novo arquivo, 2 modifica√ß√µes**

